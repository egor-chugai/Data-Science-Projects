{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в машинное обучение. Модель рекомендательной сиситемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта.\n",
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. \n",
    "\n",
    "Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится. \n",
    "Постройте модель с максимально большим значением accuracy. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте accuracy на тестовой выборке самостоятельно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных.\n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:  \n",
    "* **сalls** — количество звонков,  \n",
    "* **minutes** — суммарная длительность звонков в минутах,  \n",
    "* **messages** — количество sms-сообщений,  \n",
    "* **mb_used** — израсходованный интернет-трафик в Мб,  \n",
    "* **is_ultra** — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"0.0\"></a>Содержание.\n",
    "\n",
    "* [1. Знакомство с данными.](#1.)   \n",
    "* [2. Деление выборки на обучающую, валидационную и тестовую части.](#2.)     \n",
    "* [3. Обучение модели, подбор наилучших гиперпараметров.](#3.)     \n",
    "* [4. Проверка модели на тестовой выборке.](#4.)     \n",
    "* [5. Проверка на вменяемость.](#5.)   \n",
    "* [Вывод](#6.)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Знакомство с данными.<a name=\"1.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n"
     ]
    }
   ],
   "source": [
    "# считаем данные из файла\n",
    "df = pd.read_csv('datasets/users_behavior.csv')\n",
    "\n",
    "# посмотрим общую информацио о данных\n",
    "print(df.info()), print()\n",
    "print(df.describe()), print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка уже была произведена ранее, в датасете отсутствуют пропущенные значения, аномальные значения признаков, все столбцы переведены в соответствующие типы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Деление выборки на обучающую, валидационную и тестовую части.<a name=\"2.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод train_test_split для разделения выборки на тренировочную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим выборку на train и test\n",
    "train_data, test_data = train_test_split(df, test_size=0.20, random_state=12345)\n",
    "\n",
    "# выделим фичи и таргеты из тренировочной выборки\n",
    "features = train_data.drop(['is_ultra'], axis=1)\n",
    "target = train_data['is_ultra']\n",
    "\n",
    "# выделим фичи и таргеты из тестовой выборки\n",
    "features_test = test_data.drop(['is_ultra'], axis=1)\n",
    "target_test = test_data['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим валидационную выборку из тренировочного датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features, target, test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки, фичи: (2056, 4) таргеты: (2056,)\n",
      "Размер валидационной выборки, фичи: (515, 4) таргеты: (515,)\n",
      "Размер тестовой выборки, фичи: (643, 4) таргеты: (643,)\n"
     ]
    }
   ],
   "source": [
    "print('Размер тренировочной выборки, фичи:', features_train.shape, 'таргеты:', target_train.shape)\n",
    "print('Размер валидационной выборки, фичи:', features_valid.shape, 'таргеты:', target_valid.shape)\n",
    "print('Размер тестовой выборки, фичи:', features_test.shape, 'таргеты:', target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обучение модели, подбор наилучших гиперпараметров.<a name=\"3.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами задача бинарной классификации. Решим задачу при помощи трех популярных моделей, попытаемся подобрать оптимальные гиперпараметры для большей точности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу при помощи модели - **Случайный лес**. Для того чтобы подобрать оптимальные гиперпараметры модели, переберем число деревьев от 1 до 50 с шагом в 10, а также максимальную глубину дерева от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7902912621359224\n",
      "Оптимальное количество деревьев: 50\n",
      "Оптимальная глубина дерева: 8\n",
      "CPU times: user 3.74 s, sys: 71.8 ms, total: 3.81 s\n",
      "Wall time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model_rf = None\n",
    "best_result_rf = 0\n",
    "best_est_rf = 0\n",
    "best_depth_rf = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range (1, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions_valid) \n",
    "        if result > best_result_rf:\n",
    "            best_model_rf = model\n",
    "            best_result_rf = result\n",
    "            best_est_rf = est\n",
    "            best_depth_rf = depth\n",
    "            \n",
    "# распечатаем наилучшие результаты\n",
    "print('Accuracy лучшей модели:', best_result_rf)\n",
    "print('Оптимальное количество деревьев:', best_est_rf)\n",
    "print('Оптимальная глубина дерева:', best_depth_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу при помощи модели - **решающее дерево.** Напишем функцию, в которой подберем оптимальные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7747572815533981\n",
      "Оптимальная глубина дерева: 8\n",
      "CPU times: user 374 ms, sys: 8.98 ms, total: 383 ms\n",
      "Wall time: 386 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model_dt = None\n",
    "best_result_dt = 0\n",
    "best_est_dt = 0\n",
    "best_depth_dt = 0\n",
    "criterions = ['entropy', 'gini']\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    for criterion in criterions:\n",
    "        model = DecisionTreeClassifier(random_state=12345, criterion=criterion, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions_valid) \n",
    "        if result > best_result_dt:\n",
    "            best_model_dt = model\n",
    "            best_result_dt = result\n",
    "            best_est_dt = est\n",
    "            best_depth_dt = depth\n",
    "            \n",
    "# распечатаем наилучшие результаты\n",
    "print('Accuracy лучшей модели:', best_result_dt)\n",
    "print('Оптимальная глубина дерева:', best_depth_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессиия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу при помощи модели - **Логистическая регрессия.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7165048543689321\n",
      "CPU times: user 102 ms, sys: 6.13 ms, total: 108 ms\n",
      "Wall time: 64 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegression(random_state=12345) \n",
    "model_lr.fit(features_train, target_train) \n",
    "result_lr = model_lr.score(features_valid, target_valid)\n",
    "\n",
    "            \n",
    "# распечатаем наилучшие результаты\n",
    "print('Accuracy лучшей модели:', result_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Проверка модели на тестовой выборке.<a name=\"4.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим обученные модели на тестовой выборке и поймем какая обладает наибольшей точностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели Случайный лес: 0.8040435458786936\n",
      "Accuracy модели Решающее дерево: 0.7822706065318819\n",
      "Accuracy модели Логистическая регрессия: 0.76049766718507\n"
     ]
    }
   ],
   "source": [
    "# проверим точность модели случайный лес\n",
    "predictions_test_rf = best_model_rf.predict(features_test)\n",
    "test_accuracy_rf = accuracy_score(target_test, predictions_test_rf) \n",
    "\n",
    "# проверим точность модели решающее дерево\n",
    "predictions_test_dt = best_model_dt.predict(features_test)\n",
    "test_accuracy_dt = accuracy_score(target_test, predictions_test_dt) \n",
    "\n",
    "# проверим точность модели логистическая регрессия\n",
    "result_lr = model_lr.score(features_test, target_test)\n",
    "\n",
    "\n",
    "print('Accuracy модели Случайный лес:', test_accuracy_rf)\n",
    "print('Accuracy модели Решающее дерево:', test_accuracy_dt)\n",
    "print('Accuracy модели Логистическая регрессия:', result_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Проверка на вменяемость.<a name=\"5.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним точность полученных нами моделей с \"глупой моделью\". Реализуем её с помощью модуля DummyClassifier.\n",
    "Используем стратегию constant. В случае нашей задачи мы прогнозируем значения 1 и 0. Зададим эти констатны DummyClassifier и посмотрим насколько точность нашей модели выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность 'глупой модели' с константой 1: 0.3048211508553655\n",
      "Точность 'глупой модели' с константой 0: 0.6951788491446346\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_1 = DummyClassifier(strategy=\"constant\", random_state=0, constant=1)\n",
    "dummy_clf_1.fit(features_train, target_train)\n",
    "\n",
    "dummy_clf_0 = DummyClassifier(strategy=\"constant\", random_state=0, constant=0)\n",
    "dummy_clf_0.fit(features_train, target_train)\n",
    "\n",
    "result_1 = dummy_clf_1.score(features_test, target_test)\n",
    "result_0 = dummy_clf_0.score(features_test, target_test)\n",
    "\n",
    "print(\"Точность 'глупой модели' с константой 1:\", result_1)\n",
    "print(\"Точность 'глупой модели' с константой 0:\", result_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Относительно высокое значение показала модель с констатой 0. Это обусловлено тем, 0 в нашей выборке это тариф Смарт, он популярнее тарифа Ультра, и как видно встречается в тестовой выборке в 69,5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод<a name=\"6.\"></a>\n",
    "[к содержанию](#0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход были получены данные, не требующие предварительной обработки. Методом train_test_split выборка была разделена на обучающую, валидационную и тестовую части. Были проверены 3 популярные модели машиннного обучения: решающее дерево, случайный лес и логистическая регрессия. При обучении моделе подбирались оптимальные гиперпараметры для большей точности. Модели с наилучшими гиперпараметрами были проверены на тестовой выборке. Наилучшей моделью для решения задачи оказался случайный лес, который показал точность 80%. Также было проведено сравнение лучшей модели с \"глупой моделью\" с помощью модуля DummyClassifier. Точность лучшей полученной модели оказалась на 10% выше точности глупой модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
